{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1 \n",
    "\n",
    "# | What is an LDA? |\n",
    "The first question requires the student to create a Fisher's style Linear Discriminant Analysis class, in the way that scikit learn usually does it (with a 'fit' and 'predict' function). A Linear Discriminant Analysis (LDA, for short) is commonly used in supervised learning (labels are provided), and is a dimensionality reduction technique. What this means is that it is used to project data in a higher dimension space to a lower dimension space, and to perform separation of two or more classes. Regarding the last statement, when analyzing an LDA graphic output, often times a line can be seen: said line is used to maximize the distance between the classes' means and to minimize the variation whithin each class.\n",
    "\n",
    "# | What is Fisher's LDA? |\n",
    "Fisher's LDA is a variation of the classic Linear Discriminant Analysis in that it is 'binary': only two labelled classes can be differentiated. In reality, Fisher's LDA was the first one to be invented, and the standard LDA was invented afterwards. The real difference between the two is found in the mathematical assumptions: Fisher's LDA has 7 assumptions that must be explored and understood to correctly model it. \n",
    "The list of assumptions will be attached to this document. \n",
    "\n",
    "# | Output interpretation |\n",
    "One thousand points are created at random, and, like them, two different classes are created. Each class contains a calculated mean and covariance. The separation line is then created and, when looking at other Fisher discriminants (after a quick web search), it is observable that the line distanciates the two means correctly and, once again, correctly minimizes their variance inside their bounds. \n",
    "\n",
    "# | Final notes |\n",
    "Dots were not chosen for the output. Instead, thicker squares allow the reader to focus more on the 'whole' of the class and visualize more where the mean is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2197eef0190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#The subsequent class is used as the Fisher Linear Discriminant Analysis\n",
    "#The BaseEstimator and ClassifierMixin will be used in the third exercise to compare each different classifier \n",
    "class LDA(BaseEstimator, ClassifierMixin): \n",
    "         \n",
    "    def fit(self, X, Y):\n",
    "        #uniqueY is the list of unique lables; the dimensions are subsequently found\n",
    "        uniqueY = np.unique(Y)\n",
    "        n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        self.k = uniqueY.shape[0]\n",
    "        self.prior = np.zeros([self.k, 1])\n",
    "        self.mu = np.zeros([self.k, self.d])\n",
    "        mu = np.mean(X, axis = 0)\n",
    "        Xbar = X - mu\n",
    "        self.Sig = (1/n) * Xbar.T @ Xbar\n",
    "        self.invCov = np.linalg.inv(self.Sig)\n",
    "        #D holds the class specific subsets\n",
    "        D = []\n",
    "\n",
    "\n",
    "\n",
    "        for i, y in enumerate(uniqueY):           \n",
    "            Xi = X[Y == y]\n",
    "            D.append(Xi)           \n",
    "            ni = Xi.shape[0]\n",
    "            \n",
    "            self.prior[i] = ni / n\n",
    "            \n",
    "            self.mu[i] = np.mean(Xi, axis = 0)\n",
    "        #B is the between class scatter matrix, and using it, the dominant eigenvectors\n",
    "        #are computed. B is the product of the difference between the first and second of the class specific subset mean \n",
    "        # and the transpose of the same difference \n",
    "        #Z holds the center class matrices, which are the singular elements of D minus each transpose of the mean\n",
    "        B  =((np.atleast_2d(self.mu[0] - self.mu[1]).T) @ np.atleast_2d(self.mu[0] - self.mu[1]))\n",
    "        Z = []\n",
    "        for i, di in enumerate(D):\n",
    "            Z.append(di - self.mu[i])\n",
    "        #S holds the between scatter matrices, which are the center class matrices multiplied by their transpose \n",
    "        S = []\n",
    "        for Zi in Z:\n",
    "            S.append(Zi.T @ Zi)\n",
    "        #S total s the within class scatter matrix, which is the summation of the first and second element of S \n",
    "        STot = S[0] + S[1]\n",
    "\n",
    "\n",
    "        self.w = np.linalg.inv(STot) @ np.atleast_2d(self.mu[0] - self.mu[1]).T\n",
    "        self.w = self.w / np.linalg.norm(self.w)\n",
    "        #The function returns the dominant eigenvector.\n",
    "        return self.w\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "       mu = (self.mu[0] + self.mu[1]) / 2\n",
    "       Y = []\n",
    "\n",
    "       for x in X:\n",
    "           d = np.atleast_2d(x - mu) @ self.w\n",
    "           y = 0 if d>0 else 1\n",
    "           Y.append(y)\n",
    "        \n",
    "       return Y\n",
    "#1000 random points are selected and two different means are created, from two different arrays.\n",
    "numberOfPoints = 1000\n",
    "#Their covariance is also calculated, and the first dataset is created using this information. \n",
    "mean1 = np.array([-1, -1])\n",
    "covariance1 = np.array([[6, 0], [0, 6]])\n",
    "X1 = np.random.multivariate_normal(mean1, covariance1, numberOfPoints)\n",
    "#The second dataset is created in the same way.\n",
    "mean2 = np.array([5, 5])\n",
    "covariance2 = np.array([[6, 4], [4, 6]])\n",
    "X2 = np.random.multivariate_normal(mean2, covariance2, numberOfPoints)\n",
    "#The total X is a single array made up of the vertical stacking of X1 and X2\n",
    "#while Y is a horizontal array of the number of points times specific values.\n",
    "X = np.vstack((X1, X2))\n",
    "Y = np.hstack((numberOfPoints * [0], numberOfPoints * [1]))\n",
    "#Values are trained and tested\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25, random_state = 1)\n",
    "#The model is created and fitted to w\n",
    "model = LDA()\n",
    "w = model.fit(trainX, trainY)\n",
    "#In addition, the mean is calculated, and with it, the differentiation line is plotted along with the chart.\n",
    "mu = (np.mean(trainX[:,0]), np.mean(trainX[:,1]))\n",
    "w = 10*w\n",
    "x = [mu[0] - w[0], mu[0] + w[0]]\n",
    "y = [mu[1] - w[1], mu[1] + w[1]]\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "\n",
    "plt.plot(x,y)\n",
    "#The marker is usually '.', but I chosen ',' to make the singular points bigger and \n",
    "#render the difference clearer.\n",
    "plt.scatter(trainX[:,0], trainX[:,1], c = trainY, marker = ',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2\n",
    "# | What is a DANN |\n",
    "The second question had the students model another type of classifier: DANN. Dann stands for Discriminant Adaptive Nearest Neighbour and, as the name suggest, is very similar to the \"K Nearest Neighbor\" model. DANN is a very thorough classifier, however this characteristic, as we shall see later, also renders it very slow. DANN accepts more then two classes; in this case, three classes are used, and the third class is going to be generated in the same way as the previous two, in the previous exercise. A classification report is then printed, along with a classification matrix.\n",
    "\n",
    "# | Output interpreation |\n",
    "The classification report clearly shows that the first class (class 0) is the most accurate, and the other two follow in ascending order. If the classification report is not enough, this can also be viewed using the classification matrix, with a brighter color being in the 0-0 cell (meaning that more than 200 points of class 0 were accurately placed in class 0). In addition, through the matrix, it is clear that each class is accurate ENOUGH, as the diagonal is brightest, so more class points were accurate than not.\n",
    "\n",
    "# | Final notes |\n",
    "DANN is the classifier with the least amount of information, either in the class notes or on the Internet. The interpreter throws various warnings when computing DANN, but the program works and gives acceptable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22656\\3993784934.py:64: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5))) #enter formula picture from article\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       249\n",
      "           1       0.60      0.53      0.57       252\n",
      "           2       0.61      0.65      0.63       249\n",
      "\n",
      "    accuracy                           0.72       750\n",
      "   macro avg       0.71      0.72      0.71       750\n",
      "weighted avg       0.71      0.72      0.71       750\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from statistics import linear_regression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import string\n",
    "import matplotlib.pyplot as plt #Used primarily to draw plots\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "#The subsequent class is used as the DANN classifier\n",
    "#The BaseEstimator and ClassifierMixin will be used in the third exercise to compare each different classifier \n",
    "\n",
    "\n",
    "class DANN(BaseEstimator, ClassifierMixin):\n",
    "     def __init__(self):\n",
    "        self.data = None\n",
    "        self.output = None\n",
    "        self.KNN = None\n",
    "        self.epsilon = 1\n",
    "    \n",
    "     def fit(self, data, output, KNN=50, epsilon=1):\n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        self.KNN = KNN\n",
    "        self.epsilon = epsilon\n",
    "        return self\n",
    "\n",
    "     def predict(self, X, k=50):\n",
    "\n",
    "        numberOfFeatures = X.shape[1]\n",
    "        outputPreds = []\n",
    "\n",
    "        for x in X:\n",
    "            distance = []\n",
    "            for element in self.data:\n",
    "                distance.append(np.linalg.norm(x-element))\n",
    "            nh = np.argsort(np.array(distance))[:self.KNN]\n",
    "            nhMean = np.mean(self.data[nh])\n",
    "            nh_labels = self.output[nh]\n",
    "\n",
    "            nClasses = np.unique(nh_labels)\n",
    "            insideCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            betweenCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            for cls in nClasses:\n",
    "                clsWeight = (np.sum(nh_labels == cls)/self.KNN)\n",
    "                clsCovar = np.cov(self.data[nh][nh_labels == cls], rowvar=False)\n",
    "                insideCovar += clsCovar * clsWeight\n",
    "                clsMean = np.mean(self.data[nh][nh_labels == cls])\n",
    "                betweenCovar += np.outer(clsMean - nhMean, clsMean - nhMean) * clsWeight\n",
    "\n",
    "           \n",
    "            wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5))) \n",
    "            bSpecial = np.dot(wSpecial, betweenCovar.dot(wSpecial))\n",
    "\n",
    "            I = np.identity(numberOfFeatures)\n",
    "            sigma = wSpecial.dot(bSpecial + self.epsilon * I).dot(wSpecial)\n",
    "            distances = []\n",
    "            for element in self.data:\n",
    "                differences = x - element\n",
    "                distnc = differences.T.dot(sigma).dot(differences)\n",
    "                distances.append(distnc)\n",
    "\n",
    "            distances = np.array(distances) \n",
    "            closest = distances.argsort()[:self.KNN] #This function is used to sort by the K-nearest-neighbor which, in this case, is 50\n",
    "            outputPred = stats.mode(self.output[closest]).mode[0] #finding mode of labels - most occuring number in labels -> outputPred\n",
    "            #outputPreds represents the number that occurs the most in labels; outputPred is then the most occuring label because the points are being \n",
    "#changed to fit with the nearest neighbor with highest density.\n",
    "            outputPreds.append(outputPred) #the chosen outputPred is appeneded to the list\n",
    "        return outputPreds #The list of total choices is predicted\n",
    "\n",
    "#1000 more points are created for this exercise\n",
    "#Along with three different means, covariances and arrays.\n",
    "numberOfPoints = 1000\n",
    "\n",
    "mean1 = np.array([-1, -1])\n",
    "covariance1 = np.array([[6, 0], [0, 6]])\n",
    "X1 = np.random.multivariate_normal(mean1, covariance1, numberOfPoints)\n",
    "\n",
    "mean2 = np.array([5, 5])\n",
    "covariance2 = np.array([[6, 4], [4, 6]])\n",
    "X2 = np.random.multivariate_normal(mean2, covariance2, numberOfPoints)\n",
    "\n",
    "mean3 = np.array([6, 6])\n",
    "covariance3 = np.array([[6,5], [5,6]])\n",
    "X3 = np.random.multivariate_normal(mean3, covariance3, numberOfPoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X is now formed with three arrays to make a vertical one\n",
    "X = np.vstack((X1, X2, X3))\n",
    "\n",
    "#And the vector of labels is once again made.\n",
    "Y = np.hstack((numberOfPoints * [0], numberOfPoints * [1], numberOfPoints * [2]))\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25, random_state = 1)\n",
    "plt.scatter(trainX[:,0], trainX[:,1], c = trainY, marker = ',')\n",
    "model = DANN()\n",
    "#The model is fitted with w and the values are predicted.\n",
    "w = model.fit(trainX, trainY)\n",
    "predictedY = model.predict(testX)\n",
    "mu = (np.mean(trainX[:,0]), np.mean(trainX[:,1]))\n",
    "#The classification report is printed \n",
    "print('Classification report: ', classification_report(testY, predictedY))\n",
    "#And the classification matrix is showed (will be explained further down)\n",
    "sn.heatmap(confusion_matrix(testY, predictedY))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 3 \n",
    "# | The comparisons |\n",
    "The third exercise is, code line wise, the longest out of all the exercises. It allows the student to compare each cassifier method we used, both in accuracy and in execution time. The two worst time - wise classifiers (the two that took the most) will then be used in later exercises. Two text files are given, one for testing data, and one for training data; they both refer to sounds recordings relating to Parkinson's disease. The models that will be confronted and cross analyzed are: Bayes, Naive Bayes, LDA, QDA, DANN, Logistic Regression, Fisher and KNN. Most of them are available through Python libraries, while the rest have already been defined by the student.\n",
    "# | Output interpretation - Who is the best and who is the worst? |\n",
    "The best classifier, time wise, is found to be KNN (approximately 0.09 seconds); the worst is DANN (more than 10 seconds), followed by Bayes (approximately 3.95 seconds). Each classifier is cross analyzed, and, other than the time, the other printed values are the 'fit time', the 'score time' and the 'test accuracy'\n",
    "# | Final notes | \n",
    "It was incredibly interesting to see the different performances of all of these different models. Logistic Regression and DANN throw warnings, but they still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes: {'fit_time': array([0.00189781, 0.00173712, 0.00215244, 0.00099707, 0.00147295]), 'score_time': array([0.55324602, 0.58075976, 0.63531184, 0.71786499, 0.70080113]), 'test_accuracy': array([0.625     , 0.82211538, 0.92788462, 0.95192308, 0.84541063])}\n",
      "Time it took: 3.768326997756958\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.80      0.89       167\n",
      "\n",
      "    accuracy                           0.80       167\n",
      "   macro avg       0.50      0.40      0.44       167\n",
      "weighted avg       1.00      0.80      0.89       167\n",
      "\n",
      "LDA: {'fit_time': array([0.01074934, 0.01057911, 0.01205325, 0.01058054, 0.01024175]), 'score_time': array([0.00099778, 0.        , 0.        , 0.        , 0.00099826]), 'test_accuracy': array([0.86057692, 0.95673077, 0.96634615, 0.98076923, 0.79227053])}\n",
      "Time it took: 0.07428169250488281\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.65      0.79       167\n",
      "\n",
      "    accuracy                           0.65       167\n",
      "   macro avg       0.50      0.33      0.39       167\n",
      "weighted avg       1.00      0.65      0.79       167\n",
      "\n",
      "Quadratic: {'fit_time': array([0.00892186, 0.00921082, 0.00636315, 0.00870061, 0.00702882]), 'score_time': array([0.00099754, 0.00102305, 0.00099683, 0.00099683, 0.00099707]), 'test_accuracy': array([0.58653846, 0.77884615, 0.90865385, 0.95192308, 0.85507246])}\n",
      "Time it took: 0.06036806106567383\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.79      0.88       167\n",
      "\n",
      "    accuracy                           0.79       167\n",
      "   macro avg       0.50      0.40      0.44       167\n",
      "weighted avg       1.00      0.79      0.88       167\n",
      "\n",
      "Fisher: {'fit_time': array([0.00467634, 0.00466609, 0.00523973, 0.00431538, 0.00391746]), 'score_time': array([0.00099802, 0.0019958 , 0.00103259, 0.00199628, 0.00263262]), 'test_accuracy': array([0.86057692, 0.95673077, 0.96634615, 0.96634615, 0.79710145])}\n",
      "Time it took: 0.03851795196533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.65      0.79       167\n",
      "\n",
      "    accuracy                           0.65       167\n",
      "   macro avg       0.50      0.33      0.39       167\n",
      "weighted avg       1.00      0.65      0.79       167\n",
      "\n",
      "Naive Bayes: {'fit_time': array([0.        , 0.00332499, 0.0016191 , 0.00099683, 0.00103521]), 'score_time': array([0.        , 0.0010004 , 0.00037336, 0.0009985 , 0.        ]), 'test_accuracy': array([0.55769231, 0.91826923, 0.91826923, 0.97115385, 0.79710145])}\n",
      "Time it toook: 0.011379241943359375\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67       167\n",
      "\n",
      "    accuracy                           0.50       167\n",
      "   macro avg       0.50      0.25      0.33       167\n",
      "weighted avg       1.00      0.50      0.67       167\n",
      "\n",
      "KNN: {'fit_time': array([0.00050712, 0.        , 0.0009985 , 0.00099754, 0.        ]), 'score_time': array([0.0120337 , 0.01912785, 0.01660538, 0.0104053 , 0.00871444]), 'test_accuracy': array([0.53365385, 0.69230769, 0.66826923, 0.68269231, 0.62801932])}\n",
      "Time it took: 0.08916592597961426\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.53      0.70       167\n",
      "\n",
      "    accuracy                           0.53       167\n",
      "   macro avg       0.50      0.27      0.35       167\n",
      "weighted avg       1.00      0.53      0.70       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: {'fit_time': array([0.08654046, 0.09300208, 0.08099008, 0.08517742, 0.08495688]), 'score_time': array([0.00096536, 0.00099707, 0.00103641, 0.0009973 , 0.00105405]), 'test_accuracy': array([0.92788462, 0.97115385, 0.95673077, 0.96634615, 0.84057971])}\n",
      "Time it took: 0.5289137363433838\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.75      0.86       167\n",
      "\n",
      "    accuracy                           0.75       167\n",
      "   macro avg       0.50      0.38      0.43       167\n",
      "weighted avg       1.00      0.75      0.86       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14256\\4181274895.py:74: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN: {'fit_time': array([0.        , 0.        , 0.        , 0.        , 0.00099993]), 'score_time': array([2.06314397, 2.02542877, 1.89095259, 2.51235223, 2.14920759]), 'test_accuracy': array([0.5       , 0.58173077, 0.46634615, 0.52403846, 0.48309179])}\n",
      "Time it took: 12.84276008605957\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.16      0.27       167\n",
      "\n",
      "    accuracy                           0.16       167\n",
      "   macro avg       0.50      0.08      0.13       167\n",
      "weighted avg       1.00      0.16      0.27       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import scipy \n",
    "from statistics import linear_regression\n",
    "import string\n",
    "import matplotlib.pyplot as plt #Used primarily to draw plots\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import stats\n",
    "from scipy.stats import mode \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "#DANN and Fisher classifier are written once more as they will be used later.\n",
    "\n",
    "\n",
    "class DANN(BaseEstimator, ClassifierMixin):\n",
    "     def __init__(self):\n",
    "        self.data = None\n",
    "        self.output = None\n",
    "        self.KNN = None\n",
    "        self.epsilon = 1\n",
    "    \n",
    "     def fit(self, data, output, KNN=50, epsilon=1):\n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        self.KNN = KNN\n",
    "        self.epsilon = epsilon\n",
    "        return self\n",
    "\n",
    "     def predict(self, X, k=50):\n",
    "        numberOfFeatures = X.shape[1]\n",
    "        outputPreds = []\n",
    "        for x in X:\n",
    "            distance = []\n",
    "            for element in self.data:\n",
    "                distance.append(np.linalg.norm(x-element))\n",
    "            nh = np.argsort(np.array(distance))[:self.KNN]\n",
    "            nhMean = np.mean(self.data[nh])\n",
    "            nh_labels = self.output[nh]\n",
    "\n",
    "            nClasses = np.unique(nh_labels)\n",
    "            insideCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            betweenCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            for cls in nClasses:\n",
    "                clsWeight = (np.sum(nh_labels == cls)/self.KNN)\n",
    "                clsCovar = np.cov(self.data[nh][nh_labels == cls], rowvar=False) \n",
    "                insideCovar += clsCovar * clsWeight\n",
    "                clsMean = np.mean(self.data[nh][nh_labels == cls])\n",
    "                betweenCovar += np.outer(clsMean - nhMean, clsMean - nhMean) * clsWeight\n",
    "            wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5))) \n",
    "            bSpecial = np.dot(wSpecial, betweenCovar.dot(wSpecial))\n",
    "            I = np.identity(numberOfFeatures)\n",
    "            sigma = wSpecial.dot(bSpecial + self.epsilon * I).dot(wSpecial) \n",
    "            distances = []\n",
    "            for element in self.data:\n",
    "                differences = x - element\n",
    "                distnc = differences.T.dot(sigma).dot(differences)\n",
    "                distances.append(distnc)\n",
    "\n",
    "            distances = np.array(distances) \n",
    "            closest = distances.argsort()[:self.KNN] \n",
    "            outputPred = stats.mode(self.output[closest]).mode[0] \n",
    "            outputPreds.append(outputPred) \n",
    "        return outputPreds \n",
    "\n",
    "\n",
    "class LDAFisher(BaseEstimator, ClassifierMixin):        \n",
    "    def fit(self, X, Y):\n",
    "        uniqueY = np.unique(Y)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        self.k = uniqueY.shape[0]\n",
    "        \n",
    "        self.prior = np.zeros([self.k, 1])\n",
    "        self.mu = np.zeros([self.k, self.d])\n",
    "        \n",
    "        mu = np.mean(X, axis = 0)\n",
    "        Xbar = X - mu\n",
    "        self.Sig = (1/n) * Xbar.T @ Xbar\n",
    "        self.invCov = np.linalg.inv(self.Sig)\n",
    "        D = []\n",
    "\n",
    "        for i, y in enumerate(uniqueY):           \n",
    "            Xi = X[Y == y]\n",
    "            D.append(Xi)           \n",
    "            ni = Xi.shape[0]\n",
    "            \n",
    "            self.prior[i] = ni / n\n",
    "            \n",
    "            self.mu[i] = np.mean(Xi, axis = 0)\n",
    "\n",
    "        B  =((np.atleast_2d(self.mu[0] - self.mu[1]).T) @ np.atleast_2d(self.mu[0] - self.mu[1]))\n",
    "        Z = []\n",
    "        for i, di in enumerate(D):\n",
    "            Z.append(di - self.mu[i])\n",
    "        \n",
    "        S = []\n",
    "        for Zi in Z:\n",
    "            S.append(Zi.T @ Zi)\n",
    "        \n",
    "        STot = S[0] + S[1]\n",
    "\n",
    "\n",
    "        self.w = np.linalg.inv(STot) @ np.atleast_2d(self.mu[0] - self.mu[1]).T\n",
    "        self.w = self.w / np.linalg.norm(self.w)\n",
    "        return self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "       mu = (self.mu[0] + self.mu[1]) / 2\n",
    "       Y = []\n",
    "\n",
    "       for x in X:\n",
    "           d = np.atleast_2d(x - mu) @ self.w\n",
    "           y = 0 if d>0 else 1\n",
    "           Y.append(y)\n",
    "        \n",
    "       return Y\n",
    "\n",
    "\n",
    "#The BayesClassifier is taken from a previous assignment and the BaseEstimator and ClassifierMixin\n",
    "#is integrated in the class \n",
    "class BayesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, Y):\n",
    "        #uniqueY is the list of unique lables; the dimensions are subsequently found\n",
    "        uniqueY = np.unique(Y)\n",
    "        n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        self.k = uniqueY.shape[0]\n",
    "        self.prior = np.zeros([self.k, 1])\n",
    "        self.mu = np.zeros([self.k, self.d])\n",
    "        self.Sigma = np.zeros([self.k, self.d, self.d])\n",
    "\n",
    "        #Sample means and covatiances are calculated\n",
    "        for i, y in enumerate(uniqueY):\n",
    "            #X is separated into its different classes, and the size of each class is found.\n",
    "            Xi = X[Y == y]\n",
    "            ni = Xi.shape[0]\n",
    "            #Priors are also found, along with the sample mean being calculated\n",
    "            self.prior[i] = ni / n\n",
    "            self.mu[i] = np.mean(Xi, axis=0)\n",
    "            #The centered data and centered covariance are also calculated\n",
    "            XiBar = Xi - self.mu[i]\n",
    "            self.Sigma[i] = (1 / ni) * XiBar.T @ XiBar\n",
    "\n",
    "    def predict(self, X):\n",
    "        n = X.shape[0]\n",
    "        posteriorPre = np.zeros([n, self.k])\n",
    "        #Posterior probabilitie's pdf is calculated \n",
    "        for i in range(n):\n",
    "            for j in range(self.k):\n",
    "                posteriorPre[i][j] = scipy.stats.multivariate_normal.pdf(X[i], self.mu[j], self.Sigma[j],\n",
    "                                                                         allow_singular=True)\n",
    "        #Along with a vector that is proportional to them\n",
    "        posterior = posteriorPre * self.prior.T\n",
    "        #By choosing the most probable class, the label for each datapoint is found.\n",
    "        predictions = np.argmax(posterior, axis=1)\n",
    "        #Such predictions are then returned\n",
    "        return predictions\n",
    "\n",
    "\n",
    "#The two different documents are read in as text files, and the names of the columns are subsequently added\n",
    "df  = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording\\\\train_data.txt')\n",
    "dfTest = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording//test_data.txt')\n",
    "\n",
    "\n",
    "df.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'UPDRS', 'class']\n",
    "df.head()\n",
    "\n",
    "dfTest.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'class']\n",
    "dfTest.head()\n",
    "#dfX is comprised of all the columns but 'class' and 'UPDRS'\n",
    "dfX  = df.drop(columns = ['class', 'UPDRS'])\n",
    "#dfY is just 'class'\n",
    "dfY = df['class']\n",
    "#Both arrays are then converted to numpy\n",
    "dfX = dfX.to_numpy()\n",
    "dfY = dfY.to_numpy()\n",
    "#The same is done for the testing set \n",
    "dfTestX = dfTest.drop(columns = ['class'])\n",
    "dfTestY = dfTest['class']\n",
    "\n",
    "dfTestX = dfTestX.to_numpy()\n",
    "dfTestY = dfTestY.to_numpy()\n",
    "\n",
    "#The following procedure is executed for each classifier:\n",
    "#1. A start time is begun, it will take the time from that instance to when the class will be called again\n",
    "#2. A model is created\n",
    "#3. The model will be cross validated (this is where BayesEstimator and ClassMixin are needed) with the central focus to its accuracy\n",
    "#4. The model is fitted \n",
    "#5 The time class is called once again and the ending times is taken\n",
    "#6. Both the cross validation result and the time it took for it to run (which is the ending time minus the starting time) are outputted\n",
    "\n",
    "#The order is:\n",
    "#1. Bayes\n",
    "#2. LDA (python library)\n",
    "#3. QDA (python library)\n",
    "#4. Fisher\n",
    "#5. Naive Bayes (python library)\n",
    "#6. KNN (python library)\n",
    "#7. Logistic Regression (python library)\n",
    "#8. DANN\n",
    "\n",
    "startBayes = time.time()\n",
    "model = BayesClassifier()\n",
    "result = cross_validate(BayesClassifier(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeBayes = time.time()\n",
    "print (\"Bayes:\", result)\n",
    "print(\"Time it took:\", runTimeBayes - startBayes)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "\n",
    "startLDA = time.time()\n",
    "model = LinearDiscriminantAnalysis()\n",
    "result = cross_validate(LinearDiscriminantAnalysis(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeLDA = time.time()\n",
    "print(\"LDA:\", result)\n",
    "print(\"Time it took:\", runTimeLDA - startLDA)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "startQDA = time.time()\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "result = cross_validate(QuadraticDiscriminantAnalysis(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeQuadratic = time.time()\n",
    "print(\"Quadratic:\", result)\n",
    "print(\"Time it took:\", runTimeQuadratic - startQDA)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "startFisher = time.time()\n",
    "model = LDAFisher()\n",
    "result = cross_validate(LDAFisher(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeFisher = time.time()\n",
    "print(\"Fisher:\", result)\n",
    "print(\"Time it took:\", runTimeFisher - startFisher)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "startNaiveBayes = time.time()\n",
    "model = GaussianNB()\n",
    "result = cross_validate(GaussianNB(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeNBayes = time.time()\n",
    "print(\"Naive Bayes:\", result)\n",
    "print(\"Time it toook:\", runTimeNBayes - startNaiveBayes)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "startKNN = time.time()\n",
    "model = KNeighborsClassifier()\n",
    "result = cross_validate(KNeighborsClassifier(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeKNN = time.time()\n",
    "print(\"KNN:\", result)\n",
    "print(\"Time it took:\", runTimeKNN - startKNN)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "startLogReg = time.time()\n",
    "model = LogisticRegression()\n",
    "result = cross_validate(LogisticRegression(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeLogReg = time.time()\n",
    "print(\"Logistic Regression:\", result)\n",
    "print(\"Time it took:\", runTimeLogReg - startLogReg)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "\n",
    "\n",
    "startDANN = time.time()\n",
    "model = DANN()\n",
    "result = cross_validate(DANN(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(dfX, dfY)\n",
    "predictedOutput = model.predict(dfTestX)\n",
    "runTimeDANN = time.time()\n",
    "print(\"DANN:\", result)\n",
    "print(\"Time it took:\", runTimeDANN - startDANN)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 4\n",
    "# | What is PCA? |\n",
    "PCA is a technique that helps with reducing the testing and training data; many times most of the data is reduntant, so reducing it in a specific way does not make much of a difference. In this example, the two worst classifier, from the previous exercise, are chosen (Bayes and DANN), and their performance is observed after using PCA on their data. PCA stands for Principal Component Analysis.\n",
    "# | Output interpretation |\n",
    "Maybe it did not make too much of a difference, but both Bayes' and DANN's execution time has decreased, which is a positive result.\n",
    "# | Final notes |\n",
    "As in the previous exercise, DANN produces warnings, but works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes: {'fit_time': array([0.00099802, 0.        , 0.        , 0.00099754, 0.0009954 ]), 'score_time': array([0.0349412 , 0.04103327, 0.03370166, 0.03294659, 0.03287911]), 'test_accuracy': array([0.36057692, 0.47115385, 0.5       , 0.54807692, 0.43961353])}\n",
      "Time it took: 0.20641875267028809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7340\\2614394169.py:70: RuntimeWarning: invalid value encountered in power\n",
      "  wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN: {'fit_time': array([0.00099683, 0.        , 0.        , 0.00099778, 0.        ]), 'score_time': array([1.27981091, 1.34790778, 1.31876445, 1.36355996, 1.29170275]), 'test_accuracy': array([0.45192308, 0.55769231, 0.59615385, 0.47115385, 0.46859903])}\n",
      "Time it took: 7.80790638923645\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import scipy \n",
    "from statistics import linear_regression\n",
    "import string\n",
    "import matplotlib.pyplot as plt #Used primarily to draw plots\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import stats\n",
    "from scipy.stats import mode \n",
    "import warnings\n",
    "\n",
    "class DANN(BaseEstimator, ClassifierMixin):\n",
    "     def __init__(self):\n",
    "        self.data = None\n",
    "        self.output = None\n",
    "        self.KNN = None\n",
    "        self.epsilon = 1\n",
    "    \n",
    "     def fit(self, data, output, KNN=50, epsilon=1):\n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        self.KNN = KNN\n",
    "        self.epsilon = epsilon\n",
    "        return self\n",
    "\n",
    "     def predict(self, X, k=50):\n",
    "        numberOfFeatures = X.shape[1]\n",
    "        outputPreds = []\n",
    "        for x in X:\n",
    "            distance = []\n",
    "            for element in self.data:\n",
    "                distance.append(np.linalg.norm(x-element))\n",
    "            nh = np.argsort(np.array(distance))[:self.KNN]\n",
    "            nhMean = np.mean(self.data[nh])\n",
    "            nh_labels = self.output[nh]\n",
    "\n",
    "            nClasses = np.unique(nh_labels)\n",
    "            insideCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            betweenCovar = np.zeros((numberOfFeatures, numberOfFeatures))\n",
    "            for cls in nClasses:\n",
    "                clsWeight = (np.sum(nh_labels == cls)/self.KNN)\n",
    "                clsCovar = np.cov(self.data[nh][nh_labels == cls], rowvar=False) \n",
    "                insideCovar += clsCovar * clsWeight\n",
    "                clsMean = np.mean(self.data[nh][nh_labels == cls])\n",
    "                betweenCovar += np.outer(clsMean - nhMean, clsMean - nhMean) * clsWeight\n",
    "            wSpecial = np.linalg.pinv(np.nan_to_num(np.power(np.nan_to_num(insideCovar), 0.5))) \n",
    "            bSpecial = np.dot(wSpecial, betweenCovar.dot(wSpecial))\n",
    "            I = np.identity(numberOfFeatures)\n",
    "            sigma = wSpecial.dot(bSpecial + self.epsilon * I).dot(wSpecial) \n",
    "            distances = []\n",
    "            for element in self.data:\n",
    "                differences = x - element\n",
    "                distnc = differences.T.dot(sigma).dot(differences)\n",
    "                distances.append(distnc)\n",
    "\n",
    "            distances = np.array(distances) \n",
    "            closest = distances.argsort()[:self.KNN] \n",
    "            outputPred = stats.mode(self.output[closest]).mode[0] \n",
    "            outputPreds.append(outputPred) \n",
    "        return outputPreds \n",
    "\n",
    "\n",
    "#The BayesClassifier is taken from a previous assignment and the BaseEstimator and ClassifierMixin\n",
    "#is integrated in the class \n",
    "class BayesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, Y):\n",
    "        #uniqueY is the list of unique lables; the dimensions are subsequently found\n",
    "        uniqueY = np.unique(Y)\n",
    "        n = X.shape[0]\n",
    "        self.d = X.shape[1]\n",
    "        self.k = uniqueY.shape[0]\n",
    "        self.prior = np.zeros([self.k, 1])\n",
    "        self.mu = np.zeros([self.k, self.d])\n",
    "        self.Sigma = np.zeros([self.k, self.d, self.d])\n",
    "\n",
    "        #Sample means and covatiances are calculated\n",
    "        for i, y in enumerate(uniqueY):\n",
    "            #X is separated into its different classes, and the size of each class is found.\n",
    "            Xi = X[Y == y]\n",
    "            ni = Xi.shape[0]\n",
    "            #Priors are also found, along with the sample mean being calculated\n",
    "            self.prior[i] = ni / n\n",
    "            self.mu[i] = np.mean(Xi, axis=0)\n",
    "            #The centered data and centered covariance are also calculated\n",
    "            XiBar = Xi - self.mu[i]\n",
    "            self.Sigma[i] = (1 / ni) * XiBar.T @ XiBar\n",
    "\n",
    "    def predict(self, X):\n",
    "        n = X.shape[0]\n",
    "        posteriorPre = np.zeros([n, self.k])\n",
    "        #Posterior probabilitie's pdf is calculated \n",
    "        for i in range(n):\n",
    "            for j in range(self.k):\n",
    "                posteriorPre[i][j] = scipy.stats.multivariate_normal.pdf(X[i], self.mu[j], self.Sigma[j],\n",
    "                                                                         allow_singular=True)\n",
    "        #Along with a vector that is proportional to them\n",
    "        posterior = posteriorPre * self.prior.T\n",
    "        #By choosing the most probable class, the label for each datapoint is found.\n",
    "        predictions = np.argmax(posterior, axis=1)\n",
    "        #Such predictions are then returned\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "df  = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording\\\\train_data.txt')\n",
    "dfTest = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording//test_data.txt')\n",
    "\n",
    "\n",
    "df.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'UPDRS', 'class']\n",
    "df.head()\n",
    "\n",
    "dfTest.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'class']\n",
    "dfTest.head()\n",
    "#dfX is comprised of all the columns but 'class' and 'UPDRS'\n",
    "dfX  = df.drop(columns = ['class', 'UPDRS'])\n",
    "#dfY is just 'class'\n",
    "dfY = df['class']\n",
    "#Both arrays are then converted to numpy\n",
    "dfX = dfX.to_numpy()\n",
    "dfY = dfY.to_numpy()\n",
    "\n",
    "dfTestX = dfTest.drop(columns = ['class'])\n",
    "dfTestY = dfTest['class']\n",
    "\n",
    "dfTestX = dfTestX.to_numpy()\n",
    "dfTestY = dfTestY.to_numpy()\n",
    "#the PCA is set to reduce by 90%. Both the training and testing data are transformed through PCA \n",
    "pca = PCA(0.9)\n",
    "xPca = pca.fit_transform(dfX)\n",
    "testXPca = pca.transform(dfTestX)\n",
    "\n",
    "#As in the previous exercise, the same process occurs, only this time with the pca adjusted data\n",
    "startBayes = time.time()\n",
    "model = BayesClassifier()\n",
    "result = cross_validate(BayesClassifier(), xPca, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(xPca, dfY)\n",
    "predictedOutput = model.predict(testXPca)\n",
    "runTimeBayes = time.time()\n",
    "print (\"Bayes:\", result)\n",
    "print(\"Time it took:\", runTimeBayes - startBayes)\n",
    "\n",
    "\n",
    "startDANN = time.time()\n",
    "model = DANN()\n",
    "result = cross_validate(DANN(), xPca, dfY, cv = 5, scoring = ['accuracy'])\n",
    "model.fit(xPca, dfY)\n",
    "predictedOutput = model.predict(testXPca)\n",
    "runTimeDANN = time.time()\n",
    "print(\"DANN:\", result)\n",
    "print(\"Time it took:\", runTimeDANN - startDANN)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 5 \n",
    "# | What is Logistic Regression with the LASSO feature? |\n",
    "Logistic Regression is a tool used in machine learning for supervised learning, and used to calculate or predict the probability of a binary event (yes/no, for example). It can also be thought of as a statistical analysis method that predicts binary outcomes, based on an observation of the data conducted previously. LASSO, on the other hand, is a regression analysis method which both regulizes and variable selects the data, in order to make it more accurate and interpretable. In this exercise, Logistic Regression WITH the LASSO feature is used to determine which features are important and which are unimportant. \n",
    "# | Output interpretation |\n",
    "From the graph, it is obvious that the most important features are 'jitter(ddp)' and 'NTH'(almost 0.5), while features like 'Subject' seem to not matter much. Many other featurs are around the same value. 'Subject' is just the numerical value assigned to each patient, however, it is akin to name or a nickname: there is no reason to believe that somebody would get Parkinson if their name was Jerry or Hannah. 'Shimmer (apq5)' is another feature that does not seem important. When these features are taken out, the results are clear: they make a small but significant difference.\n",
    "# | Final notes |\n",
    "The absence of 'Subject' makes a notable difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE COEFFICIENT: [-1.70411027  0.029634    0.          0.          0.          0.\n",
      "  0.43484049  0.          0.         -0.21674433  0.0892014   0.03793955\n",
      "  0.          0.          0.52457767  0.02940604  0.06063679 -0.03265349\n",
      " -0.03558879 -0.00606461 -0.04710146  0.04625271  0.          0.\n",
      "  0.06095844  0.         -0.0051538 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: {'fit_time': array([0.08855271, 0.08443141, 0.09768558, 0.10041761, 0.09464574]), 'score_time': array([0.        , 0.        , 0.00051284, 0.        , 0.00101185]), 'test_accuracy': array([0.92788462, 0.97115385, 0.95673077, 0.96634615, 0.84057971])}\n",
      "Time it took: 0.4702491760253906\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.72      0.84       167\n",
      "\n",
      "    accuracy                           0.72       167\n",
      "   macro avg       0.50      0.36      0.42       167\n",
      "weighted avg       1.00      0.72      0.84       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: {'fit_time': array([0.10308123, 0.10364127, 0.09822655, 0.10429144, 0.09022403]), 'score_time': array([0.00099754, 0.00095081, 0.        , 0.        , 0.        ]), 'test_accuracy': array([0.92788462, 0.97115385, 0.95673077, 0.96634615, 0.84057971])}\n",
      "Time it took: 0.505439281463623\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.72      0.84       167\n",
      "\n",
      "    accuracy                           0.72       167\n",
      "   macro avg       0.50      0.36      0.42       167\n",
      "weighted avg       1.00      0.72      0.84       167\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df  = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording\\\\train_data.txt')\n",
    "dfTest = pd.read_csv('C:\\\\Users\\\\marti\\\\OneDrive\\\\Desktop\\\\Homework III\\\\Parkinson_Multiple_Sound_Recording//test_data.txt')\n",
    "\n",
    "\n",
    "df.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'UPDRS', 'class']\n",
    "df.head()\n",
    "\n",
    "dfTest.columns = ['Subject', 'Jitter(local)', 'Jitter(local, absolute)', 'Jitter(rap)', 'Jitter(ppq5)', 'Jitter(ddp)', 'Shimmer(local)', 'Shimmer(local, dB)', 'Shimmer(apq3)', 'Shimmer(apq5)', 'Shimmer(apq11)', 'Shimmer(dda)', 'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'class']\n",
    "dfTest.head()\n",
    "#dfX is comprised of all the columns but 'class' and 'UPDRS'\n",
    "dfX  = df.drop(columns = ['class', 'UPDRS'])\n",
    "#dfY is just 'class'\n",
    "dfY = df['class']\n",
    "#Both arrays are then converted to numpy\n",
    "dfX = dfX.to_numpy()\n",
    "dfY = dfY.to_numpy()\n",
    "#The logistic regression class is invoked and uses an l1 (LASSO) regularization, in case it overfits the data. \n",
    "logisticReg = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", C = 1.0 )\n",
    "#The data is fitted\n",
    "logisticReg.fit(dfX, dfY)\n",
    "print(\"THE COEFFICIENT:\", logisticReg.coef_[0])\n",
    "#The plot is created, with a white background, red edge color, blue bars and black lines.\n",
    "plt.figure( facecolor='white', edgecolor='red')\n",
    "\n",
    "plt.bar( range( len(logisticReg.coef_[0])) , logisticReg.coef_[0] )\n",
    "plt.xticks(range(len(logisticReg.coef_[0])), df.columns[:-2], rotation=270 )\n",
    "\n",
    "plt.ylabel('L1 Weights')\n",
    "plt.xlabel('Features')\n",
    "plt.title('Importance of Features')\n",
    "\n",
    "startLogReg = time.time()\n",
    "result = cross_validate(LogisticRegression(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "predictedOutput = logisticReg.predict(dfTestX)\n",
    "runTimeLogReg = time.time()\n",
    "print(\"Logistic Regression:\", result)\n",
    "print(\"Time it took:\", runTimeLogReg - startLogReg)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))\n",
    "\n",
    "np.delete(dfX, 0 , axis = None)\n",
    "np.delete(dfX, 9, axis = None)\n",
    "logisticReg.fit(dfX, dfY)\n",
    "plt.figure( facecolor='white', edgecolor='red')\n",
    "\n",
    "startLogReg = time.time()\n",
    "result = cross_validate(LogisticRegression(), dfX, dfY, cv = 5, scoring = ['accuracy'])\n",
    "predictedOutput = logisticReg.predict(dfTestX)\n",
    "runTimeLogReg = time.time()\n",
    "print(\"Logistic Regression:\", result)\n",
    "print(\"Time it took:\", runTimeLogReg - startLogReg)\n",
    "print('Classification report: ', classification_report(dfTestY, predictedOutput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CONSIDERATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the homework (including the Python test), this has been the most interesting and eye opening. I believe to have learned quite a lot from this particular assignment, and feel confident when tackling the argument of classifiers. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87507332e4f50a2872c10339e9e0a2ee75f341c175f9853703ef6f88953ec7f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
